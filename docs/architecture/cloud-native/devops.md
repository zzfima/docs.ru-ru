---
title: Облачная машинная DevOps
description: Создание архитектуры облачных приложений .NET для Azure | Облачная машинная DevOps
ms.date: 06/30/2019
ms.openlocfilehash: 2b3dd47eeeb69d63f5ae39705abb9d1d51295645
ms.sourcegitcommit: 559fcfbe4871636494870a8b716bf7325df34ac5
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/30/2019
ms.locfileid: "73841819"
---
# <a name="cloud-native-devops"></a>Облачная машинная DevOps

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

Любимые мантру консультантов по программному обеспечению — это вопрос, что он зависит от любого вопроса. Это не так, потому что консультанты по программному обеспечению не любят в должности. Это обусловлено тем, что в программном обеспечении нет одного действительного ответа на любые вопросы. Абсолютное право и неверно, а не баланс между противоположными.

Возьмем, к примеру, два основных школы разработки веб-приложений: одностраничные приложения (одностраничные приложения) и приложения на стороне сервера. С одной стороны, взаимодействие с пользователем, как правило, лучше с одностраничные приложения, а объем трафика к веб-серверу может быть минимальным, что позволяет разместить их на самом простом как статическое размещение. С другой стороны, одностраничные приложения, как правило, медленнее разрабатывается и усложняет тестирование. Какой из вариантов правильный? Ну, это зависит от конкретной ситуации.

Облачные приложения не могут быть неустойчивыми к тому же дичотоми. Они имеют четкие преимущества с точки зрения скорости разработки, стабильности и масштабируемости, но управление ими может быть довольно сложнее.

Лет назад, процесс перемещения приложения из среды разработки в рабочую среду и даже больше не был распространен. Компании выпустили программное обеспечение на 6-или даже каждый год. Для того, чтобы получить представление о ритмичности выпусков, которые были приемлемы до зеленых дней в Windows 10, один из них должен не обращаться к Microsoft Windows. Пять лет передаются между Windows XP и Vista, более 3 между Vista и Windows 7.

Теперь довольно хорошо установлено, что возможность выпуска программного обеспечения быстро позволяет компаниям быстро перемещаться на огромном рынке по сравнению с более слос конкурентами. Это по той причине, что основные обновления Windows 10 теперь примерно каждые шесть месяцев.

Шаблоны и методики, которые позволяют быстрее, более надежными выпусками получать ценность для бизнеса, называются DevOps. Они состоят из широкого спектра идей, охватывающих весь жизненный цикл разработки программного обеспечения, от указания приложения до предоставления и работы приложения.

DevOps появилось перед микрослужбами, и вполне вероятно, что перемещение в сторону меньшего размера, более подогнать под цели служб, было бы невозможно без DevOps, чтобы было проще выпускать и работать не только с одним, но и с большим количеством приложений в рабочей среде.

![Рис. 11-0. тенденции поиска показывают, что рост в микрослужбах не начинается, пока DevOps не станет довольно хорошо установленной идеей.](./media/microservices-vs-devops.png)

Используя хорошие DevOpsные методики, можно реализовать преимущества облачных приложений, не суффокатинг в течение горного объема работы, фактически работающих с приложениями.

Нет золотого по, когда дело доходит до DevOps. Никто не может продавать полностью и полностью охватываемое решение для выпуска и эксплуатации высококачественных приложений. Это связано с тем, что каждое приложение имеет разные отличия от других. Однако существуют средства, которые могут сделать DevOps гораздо менее непростой задачей. Один из этих средств называется Azure DevOps.

## <a name="azure-devops"></a>Azure DevOps

Azure DevOps имеет долгий Педигри. Он может возвращаться к корням, когда Team Foundation Server сначала перешли в режим «в сети» и с помощью различных изменений имени: Visual Studio Online и Visual Studio Team Services. В течение многих лет он стал намного больше, чем его предшественники.

DevOps Azure делится на пять основных компонентов:

![Рис. 11-1. пять основных областей Azure DevOps](./media/devops-components.png)

**Azure Boards** — предоставляет средство отслеживания проблем и рабочих элементов, которое позволяет пользователям выбирать наиболее подходящие для них рабочие процессы. Он включает ряд предварительно настроенных шаблонов, включая те, которые поддерживают методологии SCRUM и канбана для разработки.

**Azure Repos** — управление исходным кодом, которое поддерживает система управления версиями Team Foundation почтенный (TFVC) и любимый в отрасли Git. Запросы на вытягивание предоставляют способ включения кода для социальных сетей, позволяя обсуждать изменения по мере их внесения.

**Azure pipelines** — система управления сборками и выпусками, которая поддерживает тесную интеграцию с Azure. Сборки можно запускать на различных платформах из Windows в Linux до MacOS. Агенты сборки могут быть подготовлены в облаке или в локальной среде.

**Azure Test Plans** — отсутствие контроля качества не будет продолжено с помощью функции управления тестированием и произвольного тестирования, предоставляемой компонентом Test plans.

**Azure Artifacts** — канал артефактов, позволяющий компаниям создавать собственные, внутренние версии NuGet, NPM и другие. В случае сбоя централизованного репозитория он выполняет роль кэша вышестоящего пакета.

Подразделение верхнего уровня в Azure DevOps называется проектом. В каждом проекте различные компоненты, такие как Azure Artifacts, могут быть включены и отключены. Если пользователи хотят управлять своим исходным кодом в GitHub, но по-прежнему используют преимущества Azure Pipelines, это вполне возможно. На самом деле многие проекты с открытым исходным кодом используют [Бесплатные сборки](https://azure.microsoft.com/blog/announcing-azure-pipelines-with-unlimited-ci-cd-minutes-for-open-source/) , предлагаемые Azure DevOps, сохраняя исходный код на GitHub. Некоторые важные проекты с открытым исходным кодом, такие как [Visual Studio Code](https://code.visualstudio.com/), [Yarn](https://yarnpkg.com/en/), [gulp](https://gulpjs.com/)и [NumPy](https://www.numpy.org/) , внесли переход.

Каждый из этих компонентов предоставляет некоторые преимущества для собственных облачных приложений, но наиболее полезными являются системы управления версиями, доски и конвейеры.  

## <a name="source-control"></a>Система управления версиями

Организация кода для собственного облачного приложения может оказаться сложной задачей. Вместо одного огромного приложения облачные приложения, как правило, состоят из веб-приложений небольших приложений, взаимодействующих друг с другом. Как и в случае с любыми вычислениями, лучшее расположение кода остается открытым вопросом. Существуют примеры успешных приложений, использующих различные виды макетов, но у двух вариантов кажется наиболее популярность.

Прежде чем приступить к фактическому управлению исходным кодом, возможно, стоит выбрать, сколько проектов подходит. В рамках одного проекта поддерживается несколько репозиториев и создаются конвейеры. Доски немного сложнее, но в рамках одного проекта задачи можно легко назначить нескольким командам. Вы наверняка можете поддерживать сотни, даже тысячи разработчиков, из одного проекта Azure DevOps. Это, скорее всего, лучший подход, так как он предоставляет единое место для работы всех разработчиков и снижает путаницу при поиске одного приложения, когда разработчики не уверены в том, в каком проекте он находится.

Разделение кода для микрослужб в проекте Azure DevOps может быть несколько более сложным.

![Рис. 11-2. Сравнение одного и нескольких репозиториев](./media/single-repository-vs-multiple.png)

### <a name="repository-per-microservice"></a>Репозиторий для каждой микрослужбы

На первый взгляд, это кажется самым логичным подходом к разделению исходного кода для микрослужб. Каждый репозиторий может содержать код, необходимый для создания одной микрослужбы. Преимущества этого подхода легко видны:

1. Инструкции по созданию и обслуживанию приложения можно добавить в файл сведений в корне каждого репозитория. При зеркальном отображении репозиториев можно легко найти эти инструкции, уменьшая время запуска для разработчиков.
2. Каждая служба размещается на логическом месте, что легко можно найти, зная имя службы.
3. Сборки можно легко настроить таким способом, что они активируются только при внесении изменений в репозиторий-владелец.
4. Количество изменений, поступающих в репозиторий, ограничено небольшим количеством разработчиков, работающих над проектом.
5. Безопасность легко настроить путем ограниченного числа репозиториев, на которые разработчики имеют разрешения на чтение и запись.
6. Параметры уровня репозитория могут быть изменены группой-владельцем с минимальным обсуждением с другими пользователями.

Одной из ключевых идей микрослужб является то, что службы должны быть отделены друг от друга. При использовании проектирования на основе домена для определения границ служб, которые службы выполняют в качестве границ транзакций. Обновления базы данных не должны охватывать несколько служб. Эта коллекция связанных данных называется ограниченным контекстом.  Эта идея отражается изоляцией данных микрослужбы в отдельную и автономную базу данных от остальных служб. В этом случае очень важно обеспечить эту идею до исходного кода.

Однако этот подход не имеет проблем. Одной из самых прохладное проблем разработки является управление зависимостями. Рассмотрим число файлов, составляющих средний `node_modules` Directory. Новая установка примерно такой, как `create-react-app`, может привести к тысячам пакетов. Вопрос об управлении этими зависимостями — сложная задача.

Если зависимость обновляется, то нисходящие пакеты также должны обновлять эту зависимость. К сожалению, это занимается разработкой, поэтому, неизменно `node_modules` каталог, имеет несколько версий одного пакета, каждый из которых является зависимостью какого-либо другого пакета с немного другой ритмичностью. Какую версию зависимости следует использовать при развертывании приложения? Версия, которая в данный момент находится в рабочей среде? Версия, которая сейчас находится в бета-версии, но, вероятно, находится в рабочей среде на момент, когда потребитель делает его рабочей средой? Сложные проблемы, которые не устраняются просто с помощью микрослужб.

Существуют библиотеки, зависящие от широкого спектра проектов. Разделив микрослужбы по одному в каждом репозитории, можно разрешить внутренние зависимости с помощью внутреннего репозитория, Azure Artifacts. Сборки для библиотек будут отправлять свои последние версии в Azure Artifacts для внутреннего использования. Подчиненный проект по-прежнему должен быть обновлен вручную, чтобы получить зависимость от новых пакетов.

Другой недостаток представляет себя при перемещении кода между службами. Хотя было бы неплохо предполагать, что первое разделение приложения на микрослужбы составляет 100% верно, реальность заключается в том, что пресЦиент не так часто, как не допустить ошибок в подразделении служб. Таким образом, функциональность и код, которые он будет выполнять, потребуется перенести из службы в службу: репозиторий в репозиторий. При переходе из одного репозитория в другой код теряет свой журнал. Существует множество случаев, особенно в случае аудита, когда полный журнал на фрагменте кода является ценным.

Окончательный и, возможно, самый важный недостаток — координация изменений. В истинном приложении микрослужб между службами не должно быть зависимостей развертывания. Можно развернуть службы A, B и C в любом порядке, так как они имеют слабую связь. В реальности, однако, бывают случаи, когда желательно внести изменение, охватывающее несколько репозиториев в одно и то же время. Некоторые примеры включают обновление библиотеки для закрытия бреши в системе безопасности или изменение протокола связи, используемого всеми службами.

Чтобы выполнить изменение между репозиториями, необходимо выполнить фиксацию в каждом репозитории в случае успеха. Каждое изменение в каждом репозитории необходимо запросить и просмотреть отдельно. Это может быть трудно координировать и, как правило, раздражать.

Альтернативой использованию многих репозиториев является размещение всего исходного кода в огромном, всем известном, отдельном репозитории.

### <a name="single-repository"></a>Один репозиторий

При таком подходе, иногда называемом [пререпозиторием](https://danluu.com/monorepo/), весь исходный код для каждой службы помещается в один и тот же репозиторий. Сначала это кажется плохойной идеей, которая, скорее всего, сделает работу с исходным кодом неудобной. Однако для работы такого способа есть несколько отмеченных преимуществ.

Первое преимущество заключается в том, что проще управлять зависимостями между проектами. Вместо того чтобы полагаться на некоторый внешний веб-канал артефактов, проекты могут напрямую импортировать друг друга. Это означает, что обновления выполняются мгновенно, а конфликтующие версии, скорее всего, будут находиться во время компиляции на рабочей станции разработчика. По сути, сдвигая часть тестирования интеграции влево.

При перемещении кода между проектами стало проще сохранить журнал, так как файлы будут обнаружены так, как если бы они были перемещены, а не перезаписаны.

Другое преимущество заключается в том, что в рамках одной фиксации могут быть сделаны различные изменения, которые пересекают границы служб. Это снижает издержки, возникающие при наличии потенциально десятков изменений для индивидуальной проверки.

Существует множество средств, которые могут выполнять статический анализ кода для обнаружения небезопасных методик программирования или проблемного использования интерфейсов API. В мире с несколькими репозиториями потребуется выполнить итерацию каждого репозитория, чтобы найти проблемы в них. Единый репозиторий позволяет выполнять анализ всего в одном месте.

Подход единого репозитория также имеет множество недостатков. Одна из самых невероятных проблем заключается в том, что наличие единого репозитория вызывает проблемы безопасности. Если содержимое репозитория теряется в репозитории для каждой модели службы, то объем потерянного кода будет минимальным. В одном репозитории все, что принадлежит компании, может быть потеряно. В прошлом существовало много примеров, которые применяют все усилия по разработке игр. Наличие нескольких репозиториев предоставляет меньше контактную зону, что является очень желательным признаком в большинстве методов обеспечения безопасности.

Вероятно, размер одного репозитория быстро становится неуправляемым. Это представляет некоторые интересные последствия для производительности. Может оказаться необходимым использовать специализированные средства, такие как [Виртуальная файловая система для Git](https://vfsforgit.org/), которая изначально была разработана для улучшения работы разработчиков в группе Windows.

Часто аргумент для использования одного репозитория сводится к аргументу, который Facebook или Google используют этот метод для размещения исходного кода. Если подход достаточно хорош для этих компаний, то, конечно, это правильный подход для всех компаний. Правда, очень важно, что очень немало компаний работают с любым масштабом Facebook или Google. Проблемы, возникающие на этих масштабах, отличаются от большинства разработчиков. То, что хорошо подходит для Goose, может быть неудачным для взгляните.

В итоге можно использовать любое решение для размещения исходного кода для микрослужб. Однако в большинстве случаев затраты на управление и проектирование работы в одном репозитории не являются меажер преимуществами. Разделение кода на несколько репозиториев способствует более четкому разделению проблем и способствует автономной работе групп разработчиков.  

### <a name="standard-directory-structure"></a>Стандартная структура каталогов

Независимо от спорного обсуждения в одной и нескольких репозиториях каждая служба будет иметь свой собственный каталог. Одна из лучших оптимизаций, позволяющая разработчикам быстро пересекать проекты, — поддерживать стандартную структуру каталогов.

![Рис. 11-3. Стандартная структура каталогов для служб электронной почты и входа в систему](./media/dir-struct.png)

При создании нового проекта следует использовать шаблон, который помещает на месте правильную структуру. Этот шаблон также может включать такие полезные элементы как скелет файла README и `azure-pipelines.yml`. В любой архитектуре микрослужб высокая степень вариативности между проектами усложняет работу с службами.

Существует множество средств, которые могут предоставить шаблоны для всего каталога, содержащего несколько каталогов исходного кода. [Yeoman](https://yeoman.io/) является популярным в мире JavaScript, и GitHub недавно выпустила [шаблоны репозитория](https://github.blog/2019-06-06-generate-new-repositories-with-repository-templates/), которые обеспечивают многие функции.

## <a name="task-management"></a>Управление задачами

Управление задачами в любом проекте может быть затруднительным. На самом себе есть бесчисленные вопросы о том, какие рабочие процессы необходимо настроить для обеспечения оптимальной производительности разработчиков.

Облачные приложения, как правило, меньше традиционных программных продуктов, или по крайней мере они делятся на более мелкие службы. Отслеживание проблем или задач, связанных с этими службами, остается так же важным, как и для любого другого проекта программного обеспечения. Никто не хочет отказаться от какого-либо рабочего элемента или объяснить клиенту, что их проблемы не были зарегистрированы надлежащим образом. Платы настраиваются на уровне проекта, но в пределах каждого проекта области могут быть определены. Они позволяют разбить проблемы на несколько компонентов. Преимущество сохранения всей работы для всего приложения в одном месте заключается в том, что можно легко переместить рабочие элементы из одной команды в другую, так как они понятнее.

Azure DevOps поставляется с набором популярных шаблонов, которые предварительно настроены. В самой базовой конфигурации все, что необходимо для того, чтобы узнать, что такое невыполненная работа, какие пользователи работают и что делать. Важно обеспечить эту видимость процесса создания программного обеспечения, чтобы можно было назначать приоритеты и завершать задачи, сообщаемые клиенту. Разумеется, очень мало программных проектов применяют процесс так же просто, как `to do`, `doing`и `done`. Добавление в процесс таких шагов, как `QA` или `Detailed Specification`, не занимает много времени.

Одной из наиболее важных частей гибких методологий является самоанализ через регулярные интервалы. Эти проверки предназначены для получения сведений о проблемах, с которыми сталкиваются команды, и о том, как их можно улучшить. Часто это означает изменение потока проблем и функций с помощью процесса разработки. Это вполне работоспособно, чтобы расширить макеты плат с дополнительными этапами.

Этапы на досках не являются единственным средством организации. В зависимости от конфигурации доски есть иерархия рабочих элементов. Наиболее детализированный элемент, который может отображаться на доске, — это задача. В этом случае задача содержит поля для заголовка, описания, приоритета, оценки объема оставшейся работы и возможность связывания с другими рабочими элементами или элементами разработки (ветви, фиксации, запросы на включение внесенных изменений, сборки и т. д.). Рабочие элементы можно классифицировать в разные области приложения и разные итерации (спринты), чтобы упростить их поиск.

![Рис. 11-4. пример задачи в Azure DevOps](./media/task-details.png)

Поле Description (описание) поддерживает обычные стили (полужирный, курсив, подчеркивание и зачеркивание) и возможность вставки изображений. Это делает его мощным инструментом для использования при указании рабочих или ошибок.

Задачи можно свести к функциям, которые определяют большую единицу работы. Функции, в свою очередь, могут быть [сведены в ситуаций](https://docs.microsoft.com/azure/devops/boards/backlogs/define-features-epics?view=azure-devops). Классификация задач в этой иерархии значительно упрощает понимание того, как можно развернуть большую функцию.

![Рис. 11-5. типы рабочих элементов, настроенные по умолчанию в базовом шаблоне процесса](./media/board-issue-types.png)

Существуют различные виды представлений проблем в Azure Boards. Элементы, которые еще не запланированы, отображаются в невыполненной работе. Отсюда их можно назначить спринту. Спринт — это поле времени, в течение которого должно выполняться определенное количество работы. Эта работа может включать задачи, а также разрешения билетов. После этого можно управлять целым спринтом из раздела доски спринта. В этом представлении показано, как работает ход выполнения, а также показана диаграмма с заработкой, которая позволяет получить постоянно обновляемое значение, если спринт будет успешным.

![Рис. 11-6. доска с определенным спринтом](./media/sprint-board.png)

К этому моменту вы должны быть очевидны, что в Azure DevOps есть большой опыт работы с досками. Разработчикам доступны простые представления о том, над чем работает. Руководители проектов просматривает предстоящие работы, а также общие сведения о существующей работе. Для руководителей существует множество отчетов об использовании источников и емкости. К сожалению, нет ничего Magical о собственных приложениях в облаке, которые устраняют необходимость в отслеживании работы. Но если необходимо отвестись от работы, существует несколько мест, в которых качество работы выше, чем в Azure DevOps.

## <a name="cicd-pipelines"></a>Конвейеры CI/CD

Практически без изменений в жизненном цикле разработки программного обеспечения было настолько революционным, как и появление непрерывной интеграции (CI) и непрерывной поставки (CD). Создание и выполнение автоматических тестов для исходного кода проекта, как только после возврата изменений происходит перехват ошибок, на ранних этапах. До появления сборки непрерывной интеграции не пришлось бы часто извлекать код из репозитория и обнаруживать, что он не прошел тесты или даже не может быть построен. Это привело к большому числу отслеженного источника.

Традиционное поставку программного обеспечения в рабочую среду требовало обширной документации и списка шагов. Каждое из этих действий необходимо выполнить вручную в процессе, подверженном ошибкам.

![Рис. 11-7. Контрольный список](./media/checklist.png)

Связанное непрерывной интеграции — непрерывная доставка, в которой собранные пакеты развертываются в среде. Ручной процесс не может масштабироваться в соответствии со скоростью разработки, поэтому Автоматизация станет более важной. Контрольные списки заменяются сценариями, которые могут выполнять одни и те же задачи быстрее и точнее, чем любой человек.

Среда, к которой доставляется непрерывная поставка, может быть тестовой средой или, как и во многих основных компаниях, она может быть рабочей средой. Последний требует инвестиций в высококачественные тесты, которые могут дать уверенность в том, что изменение не будет приводить к нарушению рабочей среды для пользователей. Точно так же, как проблемы с непрерывной интеграцией в коде, в начале непрерывной доставки обнаруживаются проблемы в процессе развертывания.

Важность автоматизации процесса сборки и доставки противотроена облачным приложениям. Развертывания происходят чаще и в других средах, что позволяет вручную развертывать границы на невозможности.

### <a name="azure-builds"></a>Сборки Azure

Azure DevOps предоставляет набор средств для упрощения непрерывной интеграции и развертывания, чем когда-либо. Эти средства находятся в разделе Azure Pipelines. Первый из них — это сборка Azure, представляющая собой средство для запуска определений сборки на основе YAML в масштабе. Пользователи могут использовать собственные компьютеры сборки (отлично, если для сборки требуется тщательная настройка среды) или компьютер из постоянно обновляемого пула виртуальных машин, размещенных в Azure. Эти размещенные агенты сборки предварительно устанавливаются с широким спектром средств разработки для разработки не только для .NET, но и для всех приложений из Java в Python и iPhone.

DevOps включает широкий спектр стандартных определений сборки, которые можно настроить для любой сборки. Определения сборки определяются в файле с именем `azure-pipelines.yml` и возвращаются в репозиторий, чтобы их можно было использовать для управления версиями вместе с исходным кодом. Это значительно упрощает внесение изменений в конвейер сборки в ветви, так как изменения могут быть возвращены только в эту ветвь. Пример `azure-pipelines.yml` для создания веб-приложения ASP.NET на полной платформе показан на рис. 11-8.

```yml
name: $(rev:r)

variables:
  version: 9.2.0.$(Build.BuildNumber)
  solution: Portals.sln
  artifactName: drop
  buildPlatform: any cpu
  buildConfiguration: release
  
pool:
  name: Hosted VS2017
  demands:
  - msbuild
  - visualstudio
  - vstest

steps:
- task: NuGetToolInstaller@0
  displayName: 'Use NuGet 4.4.1'
  inputs:
    versionSpec: 4.4.1

- task: NuGetCommand@2
  displayName: 'NuGet restore'
  inputs:
    restoreSolution: '$(solution)'

- task: VSBuild@1
  displayName: 'Build solution'
  inputs:
    solution: '$(solution)'
    msbuildArgs: '-p:DeployOnBuild=true -p:WebPublishMethod=Package -p:PackageAsSingleFile=true -p:SkipInvalidConfigurations=true -p:PackageLocation="$(build.artifactstagingdirectory)\\"'
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'

- task: VSTest@2
  displayName: 'Test Assemblies'
  inputs:
    testAssemblyVer2: |
     **\$(buildConfiguration)\**\*test*.dll
     !**\obj\**
     !**\*testadapter.dll
    platform: '$(buildPlatform)'
    configuration: '$(buildConfiguration)'

- task: CopyFiles@2
  displayName: 'Copy UI Test Files to: $(build.artifactstagingdirectory)'
  inputs:
    SourceFolder: UITests
    TargetFolder: '$(build.artifactstagingdirectory)/uitests'

- task: PublishBuildArtifacts@1
  displayName: 'Publish Artifact'
  inputs:
    PathtoPublish: '$(build.artifactstagingdirectory)'
    ArtifactName: '$(artifactName)'
  condition: succeededOrFailed()
```

**Рис. 11-8** . пример Азуре-пипелинес. yml

В этом определении сборки используется ряд встроенных задач, которые делают создание сборок простым, как создание общенаборного набора (проще, чем гигантская Falcon). Например, задача NuGet восстанавливает пакеты NuGet, а задача Всбуилд вызывает средства сборки Visual Studio для выполнения фактической компиляции. В Azure DevOps доступны сотни различных задач с тысячами, которые поддерживаются сообществом. Вполне вероятно, что вне зависимости от того, какие задачи сборки вы хотите запустить, кто уже создал ее.

Сборки могут запускаться вручную, по расписанию или после завершения другой сборки. В большинстве случаев рекомендуется создавать при каждом возврате. Сборки можно фильтровать, чтобы разные сборки выполнялись в разных частях репозитория или в разных ветвях. Это позволяет выполнять такие сценарии, как выполнение быстрых сборок с меньшим тестированием запросов на вытягивание и выполнение полноценного набора регрессий на основе магистрали на ночь.

Конечным результатом сборки является коллекция файлов, называемых артефактами сборки. Эти артефакты можно передать на следующий шаг в процессе сборки или добавить в веб-канал артефактов Azure, чтобы они могли использоваться другими сборками.

### <a name="azure-devops-releases"></a>Выпуски Azure DevOps

Сборки позаботится о компиляции программного обеспечения в распространяемый пакет, однако артефакты по-прежнему нужно относить в тестовую среду для выполнения непрерывной поставки. Для этого Azure DevOps использует отдельное средство, именуемое выпусками. В выпусках используется библиотека тех же задач, которые были доступны для сборки, но введено понятие "этапы". Этап — это изолированная среда, в которой установлен пакет. Например, продукт может использовать разработку, контроль качества и рабочую среду. Код постоянно доставляется в среду разработки, где можно выполнять автоматические тесты. После того, как эти тесты прошли проверку, переходят в среду контроля качества для ручного тестирования. Наконец, код помещается в рабочую среду, где он виден всем.

![Рис. 11-9. пример конвейера выпуска с этапами разработки, контроля качества и производства](./media/release-pipeline.png)

Каждый этап сборки может автоматически активироваться завершением предыдущего этапа. Однако во многих случаях это нежелательно. Перемещение кода в рабочую среду может потребовать утверждения от кого бы то ни было. Выпуски поддерживают это, разрешая утверждающим на каждом шаге конвейера выпуска. Правила можно настроить таким образом, чтобы конкретный пользователь или группа людей должны выйти из выпуска, прежде чем они будут внесены в рабочую среду. Эти шлюзы позволяют проверять качество вручную, а также удовлетворять нормативным требованиям, связанным с контролем того, что происходит в рабочей среде.

### <a name="everybody-gets-a-build-pipeline"></a>Все получают конвейер сборки

Настройка многих конвейеров сборки не взимается, поэтому рекомендуется иметь хотя бы один конвейер сборки для каждой микрослужбы. В идеале микрослужбы можно развертывать независимо в любой среде, чтобы каждый из них мог быть выпущен через собственный конвейер, не освобождая массу несвязанного кода. Каждый конвейер может иметь свой собственный набор утверждений, позволяющих использовать варианты в процессе сборки для каждой службы.

### <a name="versioning-releases"></a>Версии выпусков

Недостаток использования функций выпусков заключается в том, что он не может быть определен в возвращенном файле `azure-pipelines.yml`. Существует множество причин, из-за которых определения выпуска для каждой ветви включают в себя скелет выпуска в шаблоне проекта. К счастью, работа выполняется для сдвига некоторых этапов поддержки в компонент сборки. Это будет известно как многоэтапная сборка, и [теперь доступна первая версия](https://devblogs.microsoft.com/devops/whats-new-with-azure-pipelines/).

>[!div class="step-by-step"]
>[Назад](azure-security.md)
>[Вперед](infrastructure-as-code.md)
