---
title: Выбор алгоритма ML.NET
description: Сведения о выборе алгоритма ML.NET для модели машинного обучения
author: natke
ms.topic: overview
ms.date: 06/05/2019
ms.openlocfilehash: 0721418d8b0b3c9ab645eb9885b0f4951c37762e
ms.sourcegitcommit: f348c84443380a1959294cdf12babcb804cfa987
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/12/2019
ms.locfileid: "73976700"
---
# <a name="how-to-choose-an-mlnet-algorithm"></a>Выбор алгоритма ML.NET

Для каждой [задачи ML.NET](resources/tasks.md) существует несколько возможных алгоритмов обучения. Выбор конкретного алгоритма определяется проблемой, которую вы пытаетесь решить, характеристиками данных, а также доступными вам вычислительными ресурсами и ресурсами хранения. Важно отметить, что обучение модели машинного обучения — это итеративный процесс. Может потребоваться попробовать несколько алгоритмов, чтобы определить лучший из них.

Алгоритмы работают на базе **признаков**. Признаки — это числовые значения, вычисляемые на основе входных данных. Они являются оптимальным входными данными для алгоритмов машинного обучения. Вы преобразовываете необработанные входные данные в признаки, используя одно или несколько [преобразований данных](resources/transforms.md). Например, текстовые данные преобразуются в набор из числа слов и числа сочетаний слов. После извлечения признаков из необработанных данных с помощью преобразований данных они считаются **определенными признаками**. Например, определенные признаки текста или определенные признаки данных изображения.

## <a name="trainer--algorithm--task"></a>Обучающий алгоритм = алгоритм + задача

Алгоритм — это математическое описание, используемое для создания **модели**. Различные алгоритмы дают модели с разными характеристиками.

В ML.NET один алгоритм можно применить к различным задачам. Например, стохастический двойной покоординатный подъем можно использовать для двоичной классификации, многоклассовой классификации и регрессии. Различие заключается в интерпретации выходных данных алгоритма для сопоставления с задачей.

Для каждого сочетания алгоритма и задачи ML.NET предоставляет компонент, который выполняет алгоритм обучения и осуществляет интерпретацию. Такие компоненты называются обучающими алгоритмами. Например, <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> использует алгоритм **StochasticDualCoordinatedAscent**, применяемый к задаче **регрессии**.

## <a name="linear-algorithms"></a>Линейные алгоритмы

Линейные алгоритмы создают модель, которая вычисляет **оценки** на базе линейного сочетания входных данных и набора **весовых коэффициентов**. Весовые коэффициенты — это параметры модели, оцениваемые во время обучения.

Линейные алгоритмы хорошо подходят для признаков, являющихся [линейно сепарабельными](https://en.wikipedia.org/wiki/Linear_separability).

Перед обучением с помощью линейного алгоритма нужно нормализовать признаки. Это не позволяет одному признаку оказывать большее влияние на результат по сравнению с другими признаками.

В общем случае линейные алгоритмы являются масштабируемыми и быстрыми, а также не требуют больших затрат на обучение и прогнозирование. Они масштабируются по количеству признаков и приблизительно по размеру набора данных для обучения.

Линейные алгоритмы делают несколько проходов по данным для обучения. Если набор данных помещается в память, то добавление [контрольной точки кэша](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint*) в конвейер ML.NET перед добавлением обучающего алгоритма ускорит обучение.

**Линейные обучающие алгоритмы**

|Алгоритм|Свойства|Обучающие алгоритмы|
|---------|----------|--------|
|Усредненный персептрон|Лучше всего подходит для классификации текста.|<xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>|
|Стохастический двойной покоординатный подъем|Не требуется настройка для обеспечения хорошей производительности.|<xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer>|
|L-BFGS|Используется при большом числе признаков. Создает статистику обучения логистической регрессии, но масштабируется не так хорошо, как AveragedPerceptronTrainer|<xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer>|
|Посимвольный стохастический градиентный спуск|Самый быстрый и точный линейный обучающий алгоритм двоичной классификации. Хорошо масштабируется по числу процессоров|<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>|

## <a name="decision-tree-algorithms"></a>Алгоритмы дерева принятия решений

Алгоритмы дерева принятия решений создают модель, которая содержит ряд решений: по сути, блок-схему для значений данных.

Для использования этого типа алгоритма не требуются линейно масштабируемые признаки. Кроме того, признаки не нужно нормализовывать, так как отдельные значения в векторе признаков используются независимо в процессе принятия решений.

Алгоритмы дерева принятия решений обычно очень точны.

За исключением обобщенных аддитивных моделей (GAM), модели дерева могут иметь недостаточную объясняемость, когда число признаков велико.

Алгоритмы дерева принятия решений используют больше ресурсов и хуже масштабируются по сравнению с линейными алгоритмами. Они хорошо подходят для наборов данных, помещающихся в память.

Расширенные деревья принятия решений представляют собой ансамбль небольших деревьев, где каждое дерево оценивает входные данные и передает результат следующему дереву для уточнения оценки и т. д., то есть каждое следующее дерево улучшает результат предыдущего.

**Обучающие алгоритмы деревьев принятия решений**

|Алгоритм|Свойства|Обучающие алгоритмы|
|---------|----------|--------|
|Машина слабого градиентного бустинга|Самый быстрый и точный из обучающих алгоритмов деревьев двоичной классификации. Высокие возможности настройки|<xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer>|
|Быстрое дерево|Используется для данных изображения с определенными признаками. Устойчив к несбалансированным данным. Высокие возможности настройки | <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer>|
|Быстрый лес|Отлично подходит для данных с высоким уровнем шума.|<xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer>|
|Обобщенная аддитивная модель (GAM)|Лучше всего подходит для случаев, где хорошо справляются алгоритмы дерева, но объясняемость является приоритетной задачей.|<xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer>|

## <a name="matrix-factorization"></a>Факторизация матрицы

|Свойства|Обучающие алгоритмы|
|----------|--------|
|Лучше всего подходит для разреженных категориальных данных с большими наборами данных.|<xref:Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer>|

## <a name="meta-algorithms"></a>Метаалгоритмы

Эти обучающие алгоритмы создают многоклассовый обучающий алгоритм из двоичного. Используется с <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.

|Алгоритм|Свойства|Обучающие алгоритмы|
|---------|----------|--------|
|Один против всех|Этот многоклассовый классификатор обучает один двоичный классификатор для каждого класса, который отличает этот класс от других. Масштабирование ограничено числом классов для классификации.|[OneVersusAllTrainer\<BinaryClassificationTrainer>](xref:Microsoft.ML.Trainers.OneVersusAllTrainer) |
|Попарное соединение|Этот многоклассовый классификатор обучает алгоритм двоичной классификации для каждой пары классов. Масштабирование ограничено числом классов, так как требуется обучение для каждого сочетания из двух классов.|[PairwiseCouplingTrainer\<BinaryClassificationTrainer>](xref:Microsoft.ML.Trainers.PairwiseCouplingTrainer)|

## <a name="k-means"></a>Метод k-средних

|Свойства|Обучающие алгоритмы|
|----------|--------|
|Используется для кластеризации.|<xref:Microsoft.ML.Trainers.KMeansTrainer>|

## <a name="principal-component-analysis"></a>Анализ главных компонентов

|Свойства|Обучающие алгоритмы|
|----------|--------|
|Используется для обнаружения отклонений.|<xref:Microsoft.ML.Trainers.RandomizedPcaTrainer>|

## <a name="naive-bayes"></a>Упрощенный алгоритм Байеса

|Свойства|Обучающие алгоритмы|
|----------|--------|
|Этот обучающий алгоритм многоклассовой классификации используется, когда признаки являются независимыми, а набор данных невелик.|<xref:Microsoft.ML.Trainers.NaiveBayesMulticlassTrainer>|

## <a name="prior-trainer"></a>Базовый обучающий алгоритм

|Свойства|Обучающие алгоритмы|
|----------|--------|
|Этот обучающий алгоритм двоичной классификации задает базовый уровень производительности для других обучающих алгоритмов. Для обеспечения эффективности метрики других обучающих алгоритмов должны быть лучше, чем у базового. |<xref:Microsoft.ML.Trainers.PriorTrainer>|
