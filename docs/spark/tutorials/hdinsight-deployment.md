---
title: Развертывание приложения .NET для Apache Spark в Azure HDInsight
description: Узнайте, как развернуть приложение .NET для Apache Spark в HDInsight.
ms.date: 01/23/2020
ms.topic: tutorial
ms.custom: mvc
ms.openlocfilehash: 77b57463375c36444532bdd383ec4b3bfe3ab056
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/15/2020
ms.locfileid: "77504163"
---
# <a name="tutorial-deploy-a-net-for-apache-spark-application-to-azure-hdinsight"></a>Учебник. Развертывание приложения .NET для Apache Spark в Azure HDInsight

В этом учебнике описывается развертывание приложения .NET для Apache Spark в облаке с помощью кластера Azure HDInsight. HDInsight упрощает создание и настройку кластера Spark в Azure, так как кластеры Spark в HDInsight совместимы со службой хранилища Azure и Azure Data Lake Storage.

В этом руководстве вы узнаете, как:

> [!div class="checklist"]
>
> * Получить доступ к учетным записям хранения с помощью Обозревателя службы хранилища Azure.
> * Создать кластер Azure HDInsight.
> * Опубликовать приложение .NET для Apache Spark.
> * Создать и запустить действие скрипта HDInsight.
> * Запустить приложение .NET для Apache Spark в кластере HDInsight.

## <a name="prerequisites"></a>Предварительные требования

Прежде чем начать, сделайте следующее.

* Если у вас еще нет подписки Azure, создайте [бесплатную учетную запись Azure](https://azure.microsoft.com/free/).
* Войдите на [портале Azure](https://portal.azure.com/).
* Установите Обозреватель службы хранилища Azure на [Windows](https://go.microsoft.com/fwlink/?LinkId=708343&clcid=0x409), [Linux](https://go.microsoft.com/fwlink/?LinkId=722418&clcid=0x409) или [компьютере MacOS](https://go.microsoft.com/fwlink/?LinkId=708342&clcid=0x409).
* Пройдите учебник [.NET для Apache Spark — начало работы за 10 минут](https://dotnet.microsoft.com/learn/data/spark-tutorial/intro).

## <a name="access-your-storage-accounts"></a>Доступ к учетным записям хранения

1. Откройте обозреватель службы хранилища Azure.

2. Выберите **Добавить учетную запись** в меню слева и войдите в учетную запись Azure.

    ![Вход в учетную запись Azure из Обозревателя службы хранилища](./media/hdinsight-deployment/signin-azure-storage-explorer.png)

   После входа в систему должны отобразиться все учетные записи хранения, а также все ресурсы, отправленные в учетные записи хранения.

## <a name="create-an-hdinsight-cluster"></a>Создание кластера HDInsight

> [!IMPORTANT]
> Счета за кластеры HDInsight выставляются пропорционально за минуту, даже если вы их не используете. Обязательно удалите кластер, когда завершите его использование. Дополнительные сведения см. в разделе [Очистка ресурсов](#clean-up-resources) этого учебника.

1. Войдите на [портал Azure](https://portal.azure.com).

2. Выберите действие **Создать ресурс**. Затем выберите **HDInsight** в категории **Аналитика**.

    ![Создание ресурса HDInsight на портале Azure](./media/hdinsight-deployment/create-hdinsight-resource.png)

3. В разделе **Основные сведения** укажите следующие значения.

    |Свойство.  |Описание  |
    |---------|---------|
    |Подписка  | В раскрывающемся списке выберите одну из активных подписок Azure. |
    |Группа ресурсов | Укажите, следует ли создать новую группу ресурсов или использовать имеющуюся. Группа ресурсов — это контейнер, содержащий связанные ресурсы для решения Azure. |
    |Имя кластера | Введите имя кластера Spark в HDInsight.|
    |Местоположение   | Выберите расположение группы ресурсов. В шаблоне используется это расположение для создания кластера и его хранения по умолчанию. |
    |Тип кластера| Выберите **spark** в качестве типа кластера.|
    |Cluster version|Это поле будет автоматически заполнено версией по умолчанию после выбора типа кластера. Выберите версию Spark 2.3 или 2.4.|
    |Имя пользователя для входа в кластер| Введите имя пользователя для входа в кластер.  Имя по умолчанию — *admin*. |
    |Пароль для входа в кластер| Введите пароль для входа. |
    |Имя пользователя для Secure Shell (SSH)| Введите имя пользователя SSH. По умолчанию эта учетная запись использует тот же пароль, что и учетная запись *для входа в кластер*. |

4. По завершении выберите **Next: Storage >>** (Далее: хранилище), чтобы перейти на страницу **Хранилище**. На странице **Хранилище** укажите следующие значения.

    |Свойство.  |Описание  |
    |---------|---------|
    |Тип первичного хранилища|Используйте значение **службы хранилища Azure** по умолчанию.|
    |Метод выбора|Используйте значение **Выбрать в списке** по умолчанию.|
    |Основную учетную запись хранения|Выберите подписку и одну из активных учетных записей хранения в этой подписке.|
    |Контейнер|Этот контейнер является конкретным контейнером больших двоичных объектов в вашей учетной записи хранения, где кластер ищет файлы для запуска приложения в облаке. Можно присвоить ему любое доступное имя.|

5. В разделе **Просмотр и создание** выберите **Создать**. Процесс создания кластеров занимает около 20 минут. Прежде чем перейти к следующему шагу, вы должны создать кластер.

## <a name="publish-your-app"></a>Публикация приложения

Затем вы публикуете приложение *mySparkApp*, созданное в учебнике [.NET для Apache Spark — начало работы за 10 минут](https://dotnet.microsoft.com/learn/data/spark-tutorial/intro), чтобы кластер Spark получил доступ ко всем файлам, которые необходимы для запуска приложения.

1. Для публикации *mySparkApp* выполните следующие команды:

   **В Windows:**

   ```dotnetcli
   cd mySparkApp
   dotnet publish -c Release -f netcoreapp3.0 -r ubuntu.16.04-x64
   ```

   **В Linux:**

   ```bash
   cd mySparkApp
   foo@bar:~/path/to/app$ dotnet publish -c Release -f netcoreapp3.0 -r ubuntu.16.04-x64
   ```

2. Выполните следующие задачи и заархивируйте опубликованные файлы приложения, чтобы их можно было легко передать в кластер HDInsight.

   **В Windows:**

   Перейдите в каталог *mySparkApp/bin/Release/netcoreapp3.0/ubuntu.16.04-x64*. Затем щелкните правой кнопкой мыши папку **Publish** и выберите **Отправить > Сжатая ZIP-папка**. Назовите папку **publish.zip**.

   **В Linux выполните следующую команду:**

   ```bash
   zip -r publish.zip
   ```

## <a name="upload-files-to-azure"></a>Отправка файлов в Azure

Затем используйте Обозреватель службы хранилища Azure, чтобы передать следующие пять файлов в контейнер больших двоичных объектов, выбранный для системы хранения данных кластера:

* Microsoft.Spark.Worker
* install-worker.sh
* publish.zip
* microsoft-spark-2.3.x-0.3.0.jar
* input.txt.

1. Откройте Обозреватель службы хранилища Azure и перейдите к своей учетной записи хранения в меню слева. Выполните детализацию до контейнера больших двоичных объектов для кластера в разделе **Контейнеры больших двоичных объектов** в вашей учетной записи хранения.

2. *Microsoft.Spark.Worker* помогает Apache Spark запускать ваше приложение, например пользовательские функции (UDF), которые вы написали. Загрузите [Microsoft.Spark.Worker](https://github.com/dotnet/spark/releases/download/v0.3.0/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.3.0.tar.gz). Затем выберите **Отправить** в Обозревателе службы хранилища Azure, чтобы отправить рабочую роль.

   ![Отправка файлов в Обозреватель службы хранилища Azure](./media/hdinsight-deployment/upload-files-to-storage.png)

3. *install-worker.sh* — это скрипт, который позволяет копировать зависимые файлы .NET для Apache Spark в узлы кластера.

   Создайте новый файл с именем **install-worker.sh** на локальном компьютере и вставьте [содержимое файла install-worker.sh](https://raw.githubusercontent.com/dotnet/spark/master/deployment/install-worker.sh), расположенного на сайте GitHub. Затем отправьте *install-worker.sh* в контейнер больших двоичных объектов.

4. Кластеру требуется файл publish.zip, содержащий опубликованные файлы приложения. Перейдите к опубликованной папке **mySparkApp/bin/Release/netcoreapp3.0/ubuntu.16.04-x64** и найдите **publish.zip**. Затем отправьте файл *publish.zip* в контейнер больших двоичных объектов.

5. Кластеру требуется код приложения, упакованный в JAR-файл. Перейдите к опубликованной папке **mySparkApp/bin/Release/netcoreapp3.0/ubuntu.16.04-x64** и найдите **microsoft-spark-2.3.x-0.3.0.jar**. Затем отправьте JAR-файл в контейнер больших двоичных объектов.

   Там может быть несколько JAR-файлов (для версий Spark 2.3.x и 2.4.x). Необходимо выбрать JAR-файл, соответствующий версии Spark, выбранной при создании кластера. Например, выберите *microsoft-spark-2.3.x-0.3.0.jar*, если вы выбрали Spark 2.3.2 во время создания кластера.

6. Кластеру требуются входные данные для приложения. Перейдите в каталог **mySparkApp** и найдите файл **input.txt**. Отправьте входной файл в каталог **user/sshuser** в контейнере больших двоичных объектов. Вы будете подключаться к кластеру по протоколу SSH, и в этой папке кластер будет искать входные данные. Файл *input.txt* — это единственный файл, отправленный в конкретный каталог.

## <a name="run-the-hdinsight-script-action"></a>Выполнения действия скрипта HDInsight

После запуска кластера и отправки файлов в Azure вы запускаете скрипт **install-worker.sh** в кластере.

1. Перейдите к кластеру HDInsight Spark на портале Azure и выберите **Действия скрипта**.

2. Выберите **+ Отправить новый** и укажите следующие значения.

   |Свойство.  |Описание  |
   |---------|---------|
   | Тип скрипта |Другой|
   | name | Установка рабочей роли|
   | URI bash-скрипта |https://mystorageaccount.blob.core.windows.net/mycontainer/install-worker.sh </br> Чтобы подтвердить этот URI, щелкните правой кнопкой мыши install-worker.sh в Обозреватель службы хранилища Azure и выберите пункт "Свойства". |
   | Типы узлов| Рабочий узел|
   | Параметры | azure </br> wasbs://mycontainer@myStorageAccount.blob.core.windows.net/Microsoft.Spark.Worker.netcoreapp2.1.linux-x64-0.6.0.tar.gz </br> /usr/local/bin

3. Выберите **Создать**, чтобы отправить скрипт.

## <a name="run-your-app"></a>Запуск приложения

1. Перейдите к кластеру HDInsight Spark на портале Azure и выберите **SSH и вход в кластер**.

2. Скопируйте данные для входа по протоколу SSH и вставьте имя для входа в терминал. Войдите в кластер, используя пароль, заданный во время создания кластера. Вы должны увидеть сообщение с приветствием в Ubuntu и Spark.

3. Используйте команду **spark-submit**, чтобы запустить приложение в кластере HDInsight. Не забудьте заменить **mycontainer** и **mystorageaccount** в примере скрипта, указав фактические имена контейнера больших двоичных объектов и учетной записи хранения.

   ```bash
   $SPARK_HOME/bin/spark-submit \
   --master yarn \
   --class org.apache.spark.deploy.dotnet.DotnetRunner \
   wasbs://mycontainer@mystorageaccount.blob.core.windows.net/microsoft-spark-2.3.x-0.6.0.jar \
   wasbs://mycontainer@mystorageaccount.blob.core.windows.net/publish.zip mySparkApp
   ```

   При запуске приложения отображается та же таблица подсчета слов из локального запуска начального приложения, записанная на консоль. Поздравляем, вы запустили свое первое приложение .NET для Apache Spark в облаке!

## <a name="clean-up-resources"></a>Очистка ресурсов

HDInsight сохраняет ваши данные в службе хранилища Azure, что позволяет безопасно удалить неиспользуемый кластер. Плата за кластеры HDInsight взимается, даже когда они не используются. Поскольку стоимость кластера во много раз превышает стоимость хранилища, экономически целесообразно удалять неиспользуемые кластеры.

Кроме того, можно выбрать имя группы ресурсов, чтобы открыть страницу группы ресурсов, а затем щелкнуть **Удалить группу ресурсов**. Вместе с группой ресурсов вы также удалите кластер Spark в HDInsight и учетную запись хранения по умолчанию.

## <a name="next-steps"></a>Следующие шаги

В этом руководстве вы развернули приложение .NET для Apache Spark в Azure HDInsight. Дополнительные сведения об HDInsight см. в документации по Azure HDInsight.

> [!div class="nextstepaction"]
> [Документация по Azure HDInsight](https://docs.microsoft.com/azure/hdinsight/)
